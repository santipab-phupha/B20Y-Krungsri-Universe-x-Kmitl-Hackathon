import pyaudio
import wave
import librosa
import pandas as pd
import tempfile
import time
import streamlit as st
from tensorflow.keras.models import load_model
import numpy as np

model = load_model('lstm_model.h5')
model_f = load_model('lstm_model_filter.h5')

# JavaScript to request microphone access
st.markdown(
    """
    <script>
    async function getMicrophoneAccess() {
        try {
            await navigator.mediaDevices.getUserMedia({ audio: true });
        } catch (err) {
            alert('Please allow microphone access in your browser settings.');
        }
    }
    getMicrophoneAccess();
    </script>
    """, unsafe_allow_html=True)

# Function to record audio with circular progress
def record_audio_with_progress(filename, duration=5, channels=1, rate=44100, chunk=1024):
    audio = pyaudio.PyAudio()

    # Start recording
    stream = audio.open(format=pyaudio.paInt16, channels=channels,
                        rate=rate, input=True,
                        input_device_index=0,  # Change this index to the correct one
                        frames_per_buffer=chunk)

    frames = []

    progress_circle = st.empty()
    progress_text = st.empty()

    start_time = time.time()
    total_frames = int(rate / chunk * duration)

    for i in range(total_frames):
        data = stream.read(chunk)
        frames.append(data)
        
        # Update progress
        elapsed_time = time.time() - start_time
        progress = min(elapsed_time / duration, 1.0)
        remaining_time = max(duration - elapsed_time, 0)

        progress_circle.markdown(
            f"""
            <div style="display: flex; justify-content: center; align-items: center; width: 150px; height: 150px; margin: 0 auto;">
                <div style="position: relative; width: 100%; height: 100%;">
                    <svg viewBox="0 0 36 36" style="position: absolute; width: 100%; height: 100%;">
                        <path d="M18 2.0845
                            a 15.9155 15.9155 0 0 1 0 31.831
                            a 15.9155 15.9155 0 0 1 0 -31.831"
                            fill="none"
                            stroke="#E0E0E0"
                            stroke-width="2"
                            stroke-dasharray="100, 100"
                        />
                        <path d="M18 2.0845
                            a 15.9155 15.9155 0 0 1 0 31.831
                            a 15.9155 15.9155 0 0 1 0 -31.831"
                            fill="none"
                            stroke="#4CAF50"
                            stroke-width="2"
                            stroke-dasharray="{progress * 100}, 100"
                        />
                    </svg>
                    <div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); font-size: 24px; font-weight: bold;">
                        {int(progress * 100)}%
                    </div>
                </div>
            </div>
            """,
            unsafe_allow_html=True
        )
        progress_text.markdown(f"Time remaining: **{remaining_time:.1f} seconds**")

    progress_text.markdown("Recording saved successfully!")

    # Stop and close the stream
    stream.stop_stream()
    stream.close()
    audio.terminate()

    # Save the recording to a file
    with wave.open(filename, 'wb') as wf:
        wf.setnchannels(channels)
        wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))
        wf.setframerate(rate)
        wf.writeframes(b''.join(frames))

# Function to convert audio to DataFrame
def audio_to_dataframe(filename):
    y, sr = librosa.load(filename)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=128)
    df = pd.DataFrame(mfccs.T)
    return df

def predict_class(df, model):
    X = df.values
    X = X.reshape((X.shape[0], 1, X.shape[1]))  # Reshape to match model input
    pred = model.predict(X)
    most_common_class = np.argmax(np.sum(pred, axis=0))
    return most_common_class

# Function to play audio
def play_audio(filename):
    st.audio(filename)

# Streamlit interface
st.title("üéôÔ∏è Baby Cry Identification üë∂")

duration = st.slider("Select duration of recording (seconds)", 1, 10, 5)

if st.button("Start Recording", use_container_width=True):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio_file:
        record_audio_with_progress(temp_audio_file.name, duration)
        st.success("Recording has been completed!")
        play_audio(temp_audio_file.name)
        # Convert audio to DataFrame and display
        df = audio_to_dataframe(temp_audio_file.name)
        # Make prediction and display result
        class_mapping_f = ['cry', 'silence', 'noise', 'laugh']
        predicted_class = predict_class(df, model_f)
        predict_filter = class_mapping_f[predicted_class]
        if predict_filter == "cry":
            class_mapping = ['hungry', 'tired', 'burping', 'belly_pain', 'discomfort']
            predicted_class = class_mapping[predicted_class]
            if predicted_class == 'hungry':
                st.markdown(
                        f"""
                        <div style='border: 2px solid blue; border-radius: 5px; padding: 5px; background-color: white;'>
                            <h3 style='text-align: center; color: green; font-size: 180%'> ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏î‡πá‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏¥‡∏ß </h3>
                            </div>
                            """,unsafe_allow_html=True
                )
                st.write("‡∏•‡∏π‡∏Å‡∏à‡∏∞‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏î‡∏π‡∏î‡∏õ‡∏≤‡∏Å‡∏î‡∏π‡∏î‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏•‡∏π‡∏Å‡∏Å‡∏¥‡∏ô‡∏ô‡∏°‡∏ó‡∏∏‡∏Å 2 - 3 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡πÉ‡∏ô‡∏ó‡∏≤‡∏£‡∏Å‡πÅ‡∏£‡∏Å‡πÄ‡∏Å‡∏¥‡∏î ‡∏ã‡∏∂‡πà‡∏á‡∏ñ‡πâ‡∏≤‡∏•‡∏π‡∏Å‡∏´‡∏¥‡∏ß‡∏°‡∏≤‡∏Å‡∏Å‡πá‡∏à‡∏∞‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ‡πÇ‡∏ß‡∏¢‡∏ß‡∏≤‡∏¢ ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà‡∏≠‡∏¢‡πà‡∏≤‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏•‡∏π‡∏Å‡∏´‡∏¥‡∏ß‡∏°‡∏≤‡∏Å‡∏à‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏ô‡∏∞")           
            if predicted_class == 'tired':
                st.markdown(
                        f"""
                        <div style='border: 2px solid blue; border-radius: 5px; padding: 5px; background-color: white;'>
                            <h3 style='text-align: center; color: green; font-size: 180%'> ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏î‡πá‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢ </h3>
                            </div>
                            """,unsafe_allow_html=True
                )
                st.write("‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô ‡πÅ‡∏•‡∏∞‡∏û‡∏≤‡∏•‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏™‡∏ñ‡∏≤‡∏ì‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏´‡πà‡∏á‡∏ô‡∏±‡πâ‡∏ô ‡∏õ‡∏•‡∏≠‡∏ö‡πÇ‡∏≠‡πã‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î")
            if predicted_class == 'burping':
                st.markdown(
                        f"""
                        <div style='border: 2px solid blue; border-radius: 5px; padding: 5px; background-color: white;'>
                            <h3 style='text-align: center; color: green; font-size: 180%'> ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏î‡πá‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏∞‡πÄ‡∏£‡∏≠ </h3>
                            </div>
                            """,unsafe_allow_html=True
                )
                st.write("‡∏à‡∏±‡∏ö‡∏•‡∏π‡∏Å‡πÄ‡∏£‡∏≠‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏¥‡∏ô‡∏ô‡∏°‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏¥‡∏ô‡∏ô‡∏° ‡∏ó‡∏≤‡∏°‡∏´‡∏≤‡∏´‡∏¥‡∏á‡∏Ñ‡πå ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏∏‡∏ì‡πÅ‡∏°‡πà‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏ô‡∏°‡∏•‡∏π‡∏Å‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏•‡∏π‡∏Å‡∏°‡∏µ‡∏•‡∏°‡πÉ‡∏ô‡∏ó‡πâ‡∏≠‡∏á ‡πÄ‡∏ä‡πà‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ñ‡∏±‡πà‡∏ß ‡∏ñ‡πâ‡∏≤‡∏•‡∏π‡∏Å‡∏Å‡∏¥‡∏ô‡∏ô‡∏°‡∏ú‡∏á‡∏Å‡πá‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏π‡∏ï‡∏£‡∏ó‡∏µ‡πà‡∏¢‡πà‡∏≠‡∏¢‡∏á‡πà‡∏≤‡∏¢")
            if predicted_class == 'belly_pain':
                st.markdown(
                        f"""
                        <div style='border: 2px solid blue; border-radius: 5px; padding: 5px; background-color: white;'>
                            <h3 style='text-align: center; color: green; font-size: 180%'> ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏î‡πá‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏ß‡∏î‡∏ó‡πâ‡∏≠‡∏á </h3>
                            </div>
                            """,unsafe_allow_html=True
                )
                st.write("‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏Ç‡πâ ‡∏≠‡∏≤‡πÄ‡∏à‡∏µ‡∏¢‡∏ô ‡∏ñ‡πà‡∏≤‡∏¢‡πÄ‡∏´‡∏•‡∏ß ‡∏Å‡∏£‡∏∞‡∏™‡∏±‡∏ö‡∏Å‡∏£‡∏∞‡∏™‡πà‡∏≤‡∏¢ ‡∏Å‡∏¥‡∏ô‡∏ô‡∏°‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á ‡∏£‡πâ‡∏≠‡∏á‡πÑ‡∏´‡πâ‡∏á‡∏≠‡πÅ‡∏á ‡∏Å‡∏£‡∏ì‡∏µ‡∏ô‡∏µ‡πâ‡∏û‡∏≤‡∏•‡∏π‡∏Å‡∏´‡∏≤‡∏´‡∏°‡∏≠")
            if predicted_class == 'discomfort':
                st.markdown(
                        f"""
                        <div style='border: 2px solid blue; border-radius: 5px; padding: 5px; background-color: white;'>
                            <h3 style='text-align: center; color: green; font-size: 180%'> ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏î‡πá‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏∂‡∏î‡∏≠‡∏±‡∏î </h3>
                            </div>
                            """,unsafe_allow_html=True
                )
                st.write("‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏∏‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏ß‡∏£‡πâ‡∏≠‡∏ô‡πÑ‡∏´‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏£‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏¢ ‡πÉ‡∏´‡πâ‡∏£‡∏µ‡∏ö‡∏û‡∏≤‡πÑ‡∏õ‡∏´‡∏≤‡∏´‡∏°‡∏≠")
        else:
            st.markdown(
                    f"""
                    <div style='border: 2px solid red; border-radius: 5px; padding: 5px; background-color: white;'>
                        <h3 style='text-align: center; color: red; font-size: 180%'> ‚ùå ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡πá‡∏Å ‚ùå </h3>
                        </div>
                        """,unsafe_allow_html=True
            )   


if st.button("auto",use_container_width=True):
    click_count = 0
    if click_count % 2 == 0:
        st.write("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏£‡πâ‡∏≤‡∏≤‡∏≤")
        if click_count % 2 == 0:
            while True:
                if click_count % 2 == 0:
                    with st.status('‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö'):
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio_file:
                            record_audio_with_progress(temp_audio_file.name, duration)
                            st.success("Recording has been completed!")
                            play_audio(temp_audio_file.name)
                            # Convert audio to DataFrame and display
                            df = audio_to_dataframe(temp_audio_file.name)
                            # Make prediction and display result
                            predicted_class = predict_class(df, model)
                            class_mapping = ['hungry', 'tired', 'burping', 'belly_pain', 'discomfort']
                            predicted_class = class_mapping[predicted_class]
                            st.markdown(
                                    f"""
                                    <div style='border: 2px solid blue; border-radius: 5px; padding: 5px; background-color: white;'>
                                        <h3 style='text-align: center; color: green; font-size: 180%'> ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏î‡πá‡∏Å‡∏Å‡∏≥‡∏•‡∏±‡∏á {predicted_class} </h3>
                                        </div>
                                        """,unsafe_allow_html=True
                            )
                else:
                    break
